[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog is about the data handled during the course of COMM 3180."
  },
  {
    "objectID": "posts/001_testing/testing.html",
    "href": "posts/001_testing/testing.html",
    "title": "David’s Test",
    "section": "",
    "text": "Testing Blog\nThis initial blog will serve to familiarize myself with the process of creating and updating the blog with GitHub and Jupiter."
  },
  {
    "objectID": "posts/003_dow2/dow2.html",
    "href": "posts/003_dow2/dow2.html",
    "title": "Dataset of the Week #2: Big5 Psychometrics Data",
    "section": "",
    "text": "For ages, the human mind and behavior have been of interest of many scientists. The whole discipline of psychology is based on gathering scientific evidence to explain our behavior. One of the many classifications derived from psychology include different personality traits. Among different frameworks, the Big 5 is the most commonly used model for personality. But what is the Big 5?\n\n\n\nBy Original: Anna Tunikova for peats.de and wikipedia Vector: EssensStrassen - https://peats.de/article/big-five-die-personlichkeit-in-funf-dimensionen, CC BY 4.0, https://commons.wikimedia.org/w/index.php?curid=113609961\n\n\nThe Big 5 consist of the 5 personality traits described in the above image. In this blog, we will explore some of the extremes within this data. Is it possible for a person to score 0 on agreeableness? Or in neuroticism? To answer this questions, we will use public data from Open Source Psychometrics Project. This data was collected through personality tests taken on their website.\nLet’s start by loading the necessary packages and data to conduct our analysis.\n\n# Loading packages\nimport pandas as pd\nimport re\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = 'jupyterlab'\nfrom IPython.display import display\n\n\n# Loading data\nbig5_df = pd.read_csv('data/openpsych_data.csv', sep='\\t')\nbig5_df.columns\n\nIndex(['race', 'age', 'engnat', 'gender', 'hand', 'source', 'country', 'E1',\n       'E2', 'E3', 'E4', 'E5', 'E6', 'E7', 'E8', 'E9', 'E10', 'N1', 'N2', 'N3',\n       'N4', 'N5', 'N6', 'N7', 'N8', 'N9', 'N10', 'A1', 'A2', 'A3', 'A4', 'A5',\n       'A6', 'A7', 'A8', 'A9', 'A10', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7',\n       'C8', 'C9', 'C10', 'O1', 'O2', 'O3', 'O4', 'O5', 'O6', 'O7', 'O8', 'O9',\n       'O10'],\n      dtype='str')\n\n\nAs we can see, the data has a lot of columns that might be useful for our analysis. The first few columns are demographic and include characteristics like race, age, and gender. The latter columns correspond to the data regarding the questions that are part of the personality test. The first letter corresponds to the personality trait, e.g. E=Extraversion, and it is followed by the number of question. Each personality trait has 10 questions. If we refer to the codebook used in Open Psychometrics, different questions must be coded differently since some of them are negatively presented. Then, we must prepare the data so we can extract as much of the relevant information as we want.\n\n\n\n\nWe will start by making sure that our demographic data is consistent and useful. Starting with race, we will map the numerical coding to the categories that they represent.\n\n# Defining the coding scheme\nrace_values = '''1=Mixed Race, 2=Arctic (Siberian, Eskimo), 3=Caucasian (European), \n4=Caucasian (Indian), 5=Caucasian (Middle East), 6=Caucasian (North African, Other), \n7=Indigenous Australian, 8=Native American, \n9=North East Asian (Mongol, Tibetan, Korean Japanese, etc), \n10=Pacific (Polynesian, Micronesian, etc), \n11=South East Asian (Chinese, Thai, Malay, Filipino, etc), 12=West African, Bushmen, Ethiopian, 13=Other, 0=missed\n'''\n\nparts = re.split(r'(?:,\\s+)?([0-9]+)=', race_values.strip())\n\nrace_keys = [int(key_val) for key_val in parts[1::2]]\nrace_values = parts[2::2]\n# mapping the numerical order to the nominal categories\nrace_mapping = dict(zip(race_keys,race_values))\nrace_mapping\n# Assigning its own column to the nominal categories in the dataset\nbig5_df=big5_df.assign(race_cat=big5_df['race'].map(race_mapping))\n\nIn the same way, we can map the numerical coding of gender to the categories they represent.\n\n# Mapping numerical to nominal categories\ngender_map = {\n    0: pd.NA,\n    1: 'male',\n    2: 'female',\n    3: 'other'\n}\n# Assigning its own column to the nominal categories in the data\nbig5_df=big5_df.assign(gender_cat=big5_df['gender'].map(gender_map))\n\n\n\n\nWe can start by obtaining the questions that represent each of our datapoints in the dataset.\n\n# mapping the questions\nquestions = '''\nE1  I am the life of the party.\nE2  I don't talk a lot.\nE3  I feel comfortable around people.\nE4  I keep in the background.\nE5  I start conversations.\nE6  I have little to say.\nE7  I talk to a lot of different people at parties.\nE8  I don't like to draw attention to myself.\nE9  I don't mind being the center of attention.\nE10 I am quiet around strangers.\nN1  I get stressed out easily.\nN2  I am relaxed most of the time.\nN3  I worry about things.\nN4  I seldom feel blue.\nN5  I am easily disturbed.\nN6  I get upset easily.\nN7  I change my mood a lot.\nN8  I have frequent mood swings.\nN9  I get irritated easily.\nN10 I often feel blue.\nA1  I feel little concern for others.\nA2  I am interested in people.\nA3  I insult people.\nA4  I sympathize with others' feelings.\nA5  I am not interested in other people's problems.\nA6  I have a soft heart.\nA7  I am not really interested in others.\nA8  I take time out for others.\nA9  I feel others' emotions.\nA10 I make people feel at ease.\nC1  I am always prepared.\nC2  I leave my belongings around.\nC3  I pay attention to details.\nC4  I make a mess of things.\nC5  I get chores done right away.\nC6  I often forget to put things back in their proper place.\nC7  I like order.\nC8  I shirk my duties.\nC9  I follow a schedule.\nC10 I am exacting in my work.\nO1  I have a rich vocabulary.\nO2  I have difficulty understanding abstract ideas.\nO3  I have a vivid imagination.\nO4  I am not interested in abstract ideas.\nO5  I have excellent ideas.\nO6  I do not have a good imagination.\nO7  I am quick to understand things.\nO8  I use difficult words.\nO9  I spend time reflecting on things.\nO10 I am full of ideas.\n'''\n# storing them in a dataset\nbig5_questions_df = pd.DataFrame([item.split('\\t') for item in questions.splitlines() if item&gt;''])\n\nNow, it is time to take the direction of the questions into account so we can obtain an accurate total for each of the participant’s traits.\n\n# mapping the factors\nfactor_map = { 1: 'E', \n               2: 'A',\n               3: 'C',\n               4: 'N',\n               5: 'O' }\nipip_df = pd.read_html('big5_questions.html', header=0)[0]\nipip_df = ipip_df.rename(columns={'Unnamed: 1': 'text', 'Unnamed: 7': 'factor_and_direction'})[['text','factor_and_direction']]\nipip_df[['factor','direction']]=ipip_df['factor_and_direction'].str.extract(r'([1-5])(.)')\nipip_df['category']=ipip_df['factor'].astype(int).map(factor_map)\nipip_df = ipip_df.assign(number=np.repeat(np.arange(1,11),5))\nipip_df = ipip_df.assign(qcode=ipip_df['category'].str.cat(ipip_df['number'].astype(str)))  \n\n\n# differentiating which items are coded negatively\nneg_items = ipip_df.query('direction==\"-\"')['qcode']\n\n# make a copy of the original dataframe for safety\nbig5_scored_df = big5_df.copy()\n\n# Reverse code the negative items\nbig5_scored_df[neg_items] = 6-big5_df[neg_items]\n\n\n# Group the questions into their respective traits\ncat_cols = {\n    cat : [f'{cat}{n+1}' for n in range(10)] \n    for cat in ('O','C','E','A','N') \n}\n# Create a column to store the total score for each trait\nfor cat, cols in cat_cols.items():\n    big5_scored_df[cat]=big5_scored_df[cols].sum(axis=1)\n\nAfter doing the proper coding, we can see that our dataset now includes a total score in each trait for each of the participants.\n\n#Showing the top cells of the current dataframe\nbig5_scored_df[['O','C','E','A','N']].head(5)\n\n\n\n\n\n\n\n\nO\nC\nE\nA\nN\n\n\n\n\n0\n43\n47\n44\n46\n49\n\n\n1\n26\n42\n22\n35\n29\n\n\n2\n45\n49\n35\n38\n14\n\n\n3\n41\n26\n22\n37\n17\n\n\n4\n34\n34\n34\n44\n30\n\n\n\n\n\n\n\n\n\n\n\nAfter we have treated our data in a way that is useful to us, we can start doing some analysis to answer our guiding questions. Once we have the column of total scores for each personality traits, we can see the distribution of the scores to get a sense of how the distribution among the sample.\n\n# Creating a boxplot of the distribution of scores of the 5 traits\nbig5_scored_df.plot(\n                    kind='box', \n                    column=['O','C','E','A','N'], \n                    figsize=(12,4)\n                    )\nplt.title('Total scores for Big 5 Personality Traits')\nplt.ylabel('Total Score')\nplt.xlabel('Big 5 Traits')\nplt.show()\n\n\n\n\n\n\n\n\nThe boxplot above shows the distribution of the scores. Since each element is coded from a number from 1 to 5 and there are 10 questions per trait, the minimum score is 10 and the maximum is 50. To that extent, we can see that the scores in Extraversion and Neuroticism cover the whole range. Additionally, the mean for both of them seems to be around 30 points, which is the middle of the range. It seems like people can really fall anywhere in the range of extraversion and neuroticism.\nOn the other hand, Openness to experience and Agreeableness seem to be inclined toward a bigger total score. Does that mean that it is harder for people to score low on openness to experience and agreeableness? Let’s explore these categories deeper.\n\n\nOpenness to experience denotes receptivity to new ideas and new experiences. It also measures creativity, curiosity, and willingness to entertain new ideas. If we were to think about people who scored low on openness, we would think of people who are very reluctant to explore and like to stay in their ways. Would any of the demographic categories influence if people could score lower on openness?\n\nbig5_scored_df.plot(by = 'race_cat',\n                    kind='box', \n                    column=['O'], \n                    figsize=(18,4),\n                    rot=70\n                    )\nplt.title('Openness Scores by Race Categories')\nplt.ylabel('Total Score')\nplt.xlabel('Race Categories')\nplt.show()\n\n\n\n\n\n\n\n\n\nbig5_scored_df.plot(by = 'gender_cat',\n                    kind='box', \n                    column=['O'], \n                    figsize=(18,4),\n                    )\nplt.title('Openness Scores by Gender Categories')\nplt.ylabel('Total Score')\nplt.xlabel('Gender Categories')\nplt.show()\n\n\n\n\n\n\n\n\nAs seen in the boxplots, we can see that categorizing your gender as ‘other’ might be an indicator of a higher score in openness. It makes sense since it does require being open to the idea of there being more than two gender categories. There does not seem to be a significant difference between female and male.\nWhen it comes to race categories, it seems like the majority of race categories score above the minimum in openness to experience. Nevertheless, people who classify themselves as European (Caucasian) or Other are the most likely to score the lowest on openness to experience. One of the possible explanations is that people of color are generally more open to experience. However, this explanation could be biased in the sense that maybe the people who would have scored lower on openness to experience would not have taken the test in the first place.\n\n\n\nAgreeableness measures kindness, helpfulness, and willingness to cooperate. People high in agreeableness are more trusting, affectionate, and altruistic; they generally display more prosocial behaviors than others. Then, if we were to think about people with lower levels of agreeableness, we would think of people who might not get well along with others or might be inconsiderate. We can look at some of the demographic data.\n\nbig5_scored_df.plot(by = 'gender_cat',\n                    kind='box', \n                    column=['A'], \n                    figsize=(18,4),\n                    )\nplt.title('Agreeableness Scores by Gender Categories')\nplt.ylabel('Total Score')\nplt.xlabel('Gender Categories')\nplt.show()\n\n\n\n\n\n\n\n\n\nbig5_scored_df.plot(by = 'race_cat',\n                    kind='box', \n                    column=['A'], \n                    figsize=(18,4),\n                    rot=70\n                    )\nplt.title('Agreeableness Scores by Race Categories')\nplt.ylabel('Total Score')\nplt.xlabel('Race Categories')\nplt.show()\n\n\n\n\n\n\n\n\nIn the case of agreeableness, there is no demographic characteristic that seems to significantly differentiate the levels of agreeableness. Then, maybe it is the case that is difficult for people to score low on agreeableness. On the other hand, it could also be selection bias in the sample. In that sense, people with lower levels of agreeableness would not have gone on the internet to tajke a personality quiz\nIn general, it might be that the people who are interested in taking an online personality quiz are the ones who generally would trust to some extent the result that it suggests. Then, in some way it makes sense that there are not that many quiztakers that score the lowest possible score on openness or agreeableness."
  },
  {
    "objectID": "posts/003_dow2/dow2.html#data-preparation",
    "href": "posts/003_dow2/dow2.html#data-preparation",
    "title": "Dataset of the Week #2: Big5 Psychometrics Data",
    "section": "",
    "text": "We will start by making sure that our demographic data is consistent and useful. Starting with race, we will map the numerical coding to the categories that they represent.\n\n# Defining the coding scheme\nrace_values = '''1=Mixed Race, 2=Arctic (Siberian, Eskimo), 3=Caucasian (European), \n4=Caucasian (Indian), 5=Caucasian (Middle East), 6=Caucasian (North African, Other), \n7=Indigenous Australian, 8=Native American, \n9=North East Asian (Mongol, Tibetan, Korean Japanese, etc), \n10=Pacific (Polynesian, Micronesian, etc), \n11=South East Asian (Chinese, Thai, Malay, Filipino, etc), 12=West African, Bushmen, Ethiopian, 13=Other, 0=missed\n'''\n\nparts = re.split(r'(?:,\\s+)?([0-9]+)=', race_values.strip())\n\nrace_keys = [int(key_val) for key_val in parts[1::2]]\nrace_values = parts[2::2]\n# mapping the numerical order to the nominal categories\nrace_mapping = dict(zip(race_keys,race_values))\nrace_mapping\n# Assigning its own column to the nominal categories in the dataset\nbig5_df=big5_df.assign(race_cat=big5_df['race'].map(race_mapping))\n\nIn the same way, we can map the numerical coding of gender to the categories they represent.\n\n# Mapping numerical to nominal categories\ngender_map = {\n    0: pd.NA,\n    1: 'male',\n    2: 'female',\n    3: 'other'\n}\n# Assigning its own column to the nominal categories in the data\nbig5_df=big5_df.assign(gender_cat=big5_df['gender'].map(gender_map))\n\n\n\n\nWe can start by obtaining the questions that represent each of our datapoints in the dataset.\n\n# mapping the questions\nquestions = '''\nE1  I am the life of the party.\nE2  I don't talk a lot.\nE3  I feel comfortable around people.\nE4  I keep in the background.\nE5  I start conversations.\nE6  I have little to say.\nE7  I talk to a lot of different people at parties.\nE8  I don't like to draw attention to myself.\nE9  I don't mind being the center of attention.\nE10 I am quiet around strangers.\nN1  I get stressed out easily.\nN2  I am relaxed most of the time.\nN3  I worry about things.\nN4  I seldom feel blue.\nN5  I am easily disturbed.\nN6  I get upset easily.\nN7  I change my mood a lot.\nN8  I have frequent mood swings.\nN9  I get irritated easily.\nN10 I often feel blue.\nA1  I feel little concern for others.\nA2  I am interested in people.\nA3  I insult people.\nA4  I sympathize with others' feelings.\nA5  I am not interested in other people's problems.\nA6  I have a soft heart.\nA7  I am not really interested in others.\nA8  I take time out for others.\nA9  I feel others' emotions.\nA10 I make people feel at ease.\nC1  I am always prepared.\nC2  I leave my belongings around.\nC3  I pay attention to details.\nC4  I make a mess of things.\nC5  I get chores done right away.\nC6  I often forget to put things back in their proper place.\nC7  I like order.\nC8  I shirk my duties.\nC9  I follow a schedule.\nC10 I am exacting in my work.\nO1  I have a rich vocabulary.\nO2  I have difficulty understanding abstract ideas.\nO3  I have a vivid imagination.\nO4  I am not interested in abstract ideas.\nO5  I have excellent ideas.\nO6  I do not have a good imagination.\nO7  I am quick to understand things.\nO8  I use difficult words.\nO9  I spend time reflecting on things.\nO10 I am full of ideas.\n'''\n# storing them in a dataset\nbig5_questions_df = pd.DataFrame([item.split('\\t') for item in questions.splitlines() if item&gt;''])\n\nNow, it is time to take the direction of the questions into account so we can obtain an accurate total for each of the participant’s traits.\n\n# mapping the factors\nfactor_map = { 1: 'E', \n               2: 'A',\n               3: 'C',\n               4: 'N',\n               5: 'O' }\nipip_df = pd.read_html('big5_questions.html', header=0)[0]\nipip_df = ipip_df.rename(columns={'Unnamed: 1': 'text', 'Unnamed: 7': 'factor_and_direction'})[['text','factor_and_direction']]\nipip_df[['factor','direction']]=ipip_df['factor_and_direction'].str.extract(r'([1-5])(.)')\nipip_df['category']=ipip_df['factor'].astype(int).map(factor_map)\nipip_df = ipip_df.assign(number=np.repeat(np.arange(1,11),5))\nipip_df = ipip_df.assign(qcode=ipip_df['category'].str.cat(ipip_df['number'].astype(str)))  \n\n\n# differentiating which items are coded negatively\nneg_items = ipip_df.query('direction==\"-\"')['qcode']\n\n# make a copy of the original dataframe for safety\nbig5_scored_df = big5_df.copy()\n\n# Reverse code the negative items\nbig5_scored_df[neg_items] = 6-big5_df[neg_items]\n\n\n# Group the questions into their respective traits\ncat_cols = {\n    cat : [f'{cat}{n+1}' for n in range(10)] \n    for cat in ('O','C','E','A','N') \n}\n# Create a column to store the total score for each trait\nfor cat, cols in cat_cols.items():\n    big5_scored_df[cat]=big5_scored_df[cols].sum(axis=1)\n\nAfter doing the proper coding, we can see that our dataset now includes a total score in each trait for each of the participants.\n\n#Showing the top cells of the current dataframe\nbig5_scored_df[['O','C','E','A','N']].head(5)\n\n\n\n\n\n\n\n\nO\nC\nE\nA\nN\n\n\n\n\n0\n43\n47\n44\n46\n49\n\n\n1\n26\n42\n22\n35\n29\n\n\n2\n45\n49\n35\n38\n14\n\n\n3\n41\n26\n22\n37\n17\n\n\n4\n34\n34\n34\n44\n30"
  },
  {
    "objectID": "posts/003_dow2/dow2.html#analysis",
    "href": "posts/003_dow2/dow2.html#analysis",
    "title": "Dataset of the Week #2: Big5 Psychometrics Data",
    "section": "",
    "text": "After we have treated our data in a way that is useful to us, we can start doing some analysis to answer our guiding questions. Once we have the column of total scores for each personality traits, we can see the distribution of the scores to get a sense of how the distribution among the sample.\n\n# Creating a boxplot of the distribution of scores of the 5 traits\nbig5_scored_df.plot(\n                    kind='box', \n                    column=['O','C','E','A','N'], \n                    figsize=(12,4)\n                    )\nplt.title('Total scores for Big 5 Personality Traits')\nplt.ylabel('Total Score')\nplt.xlabel('Big 5 Traits')\nplt.show()\n\n\n\n\n\n\n\n\nThe boxplot above shows the distribution of the scores. Since each element is coded from a number from 1 to 5 and there are 10 questions per trait, the minimum score is 10 and the maximum is 50. To that extent, we can see that the scores in Extraversion and Neuroticism cover the whole range. Additionally, the mean for both of them seems to be around 30 points, which is the middle of the range. It seems like people can really fall anywhere in the range of extraversion and neuroticism.\nOn the other hand, Openness to experience and Agreeableness seem to be inclined toward a bigger total score. Does that mean that it is harder for people to score low on openness to experience and agreeableness? Let’s explore these categories deeper.\n\n\nOpenness to experience denotes receptivity to new ideas and new experiences. It also measures creativity, curiosity, and willingness to entertain new ideas. If we were to think about people who scored low on openness, we would think of people who are very reluctant to explore and like to stay in their ways. Would any of the demographic categories influence if people could score lower on openness?\n\nbig5_scored_df.plot(by = 'race_cat',\n                    kind='box', \n                    column=['O'], \n                    figsize=(18,4),\n                    rot=70\n                    )\nplt.title('Openness Scores by Race Categories')\nplt.ylabel('Total Score')\nplt.xlabel('Race Categories')\nplt.show()\n\n\n\n\n\n\n\n\n\nbig5_scored_df.plot(by = 'gender_cat',\n                    kind='box', \n                    column=['O'], \n                    figsize=(18,4),\n                    )\nplt.title('Openness Scores by Gender Categories')\nplt.ylabel('Total Score')\nplt.xlabel('Gender Categories')\nplt.show()\n\n\n\n\n\n\n\n\nAs seen in the boxplots, we can see that categorizing your gender as ‘other’ might be an indicator of a higher score in openness. It makes sense since it does require being open to the idea of there being more than two gender categories. There does not seem to be a significant difference between female and male.\nWhen it comes to race categories, it seems like the majority of race categories score above the minimum in openness to experience. Nevertheless, people who classify themselves as European (Caucasian) or Other are the most likely to score the lowest on openness to experience. One of the possible explanations is that people of color are generally more open to experience. However, this explanation could be biased in the sense that maybe the people who would have scored lower on openness to experience would not have taken the test in the first place.\n\n\n\nAgreeableness measures kindness, helpfulness, and willingness to cooperate. People high in agreeableness are more trusting, affectionate, and altruistic; they generally display more prosocial behaviors than others. Then, if we were to think about people with lower levels of agreeableness, we would think of people who might not get well along with others or might be inconsiderate. We can look at some of the demographic data.\n\nbig5_scored_df.plot(by = 'gender_cat',\n                    kind='box', \n                    column=['A'], \n                    figsize=(18,4),\n                    )\nplt.title('Agreeableness Scores by Gender Categories')\nplt.ylabel('Total Score')\nplt.xlabel('Gender Categories')\nplt.show()\n\n\n\n\n\n\n\n\n\nbig5_scored_df.plot(by = 'race_cat',\n                    kind='box', \n                    column=['A'], \n                    figsize=(18,4),\n                    rot=70\n                    )\nplt.title('Agreeableness Scores by Race Categories')\nplt.ylabel('Total Score')\nplt.xlabel('Race Categories')\nplt.show()\n\n\n\n\n\n\n\n\nIn the case of agreeableness, there is no demographic characteristic that seems to significantly differentiate the levels of agreeableness. Then, maybe it is the case that is difficult for people to score low on agreeableness. On the other hand, it could also be selection bias in the sample. In that sense, people with lower levels of agreeableness would not have gone on the internet to tajke a personality quiz\nIn general, it might be that the people who are interested in taking an online personality quiz are the ones who generally would trust to some extent the result that it suggests. Then, in some way it makes sense that there are not that many quiztakers that score the lowest possible score on openness or agreeableness."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Data Stories",
    "section": "",
    "text": "Dataset of the Week #3: Winter Olympics Data\n\n\n\nDOW\n\nolympics\n\nsports\n\n\n\nDataset of the Week 3\n\n\n\n\n\nFeb 20, 2026\n\n\nDavid\n\n\n\n\n\n\n\n\n\n\n\n\nDataset of the Week #2: Big5 Psychometrics Data\n\n\n\nDOW\n\npsychology\n\n\n\nDataset of the Week 1\n\n\n\n\n\nFeb 13, 2026\n\n\nDavid\n\n\n\n\n\n\n\n\n\n\n\n\nDataset of the Week #1: The Weather in Philadelphia\n\n\n\nDOW\n\nweather\n\n\n\nDataset of the Week 1\n\n\n\n\n\nFeb 3, 2026\n\n\nDavid\n\n\n\n\n\n\n\n\n\n\n\n\nDavid’s Test\n\n\n\nBlog\n\n\n\nTesting Blogging\n\n\n\n\n\nJan 22, 2026\n\n\nDavid\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nvisualization\n\ndata stories\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nJan 12, 2026\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "import matplotlib.pyplot as plt"
  },
  {
    "objectID": "posts/000_test_post/index.html#stories-from-data",
    "href": "posts/000_test_post/index.html#stories-from-data",
    "title": "A test post",
    "section": "Stories from data",
    "text": "Stories from data\n\nLet’s set up some data\n\n\nx = ['A', 'B', 'C']\ny = [1, 5, 3]\n\n\nNow let’s visualize it\n\nplt.bar(x, y)\nplt.show()"
  },
  {
    "objectID": "posts/004_dow3/dow3.html",
    "href": "posts/004_dow3/dow3.html",
    "title": "Dataset of the Week #3: Winter Olympics Data",
    "section": "",
    "text": "The winter olympics are a collection of athletic events that are held once every four years. This year, the winter olympics are being hosted in Milano and Cortina, Italy. Since the first Winter Olympics in 1924, thousands of athletes have competed in a multitude of disciplines. Some of them might have also had an olympic career. What can we say about the success stories of people who competed in multiple olympic games?\n\n\n\nBy Eileen - originally posted to Flickr as I can’t believe I was here…., CC BY 2.0, https://commons.wikimedia.org/w/index.php?curid=9528796\n\n\n\n\nFor a lot of athletes, the olympic games represent the peak of their athletic career. Nevertheless, some of them might have started competing at such a young age that they’re able to participate in multiple instances of the olympic games. We can take look at a database of the winter olympics to find out which athletes have participated in more than one event.\n\n# Set Up\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n# Load Data\nwolympics_df = pd.read_csv('data/winter_olympics_medals.csv')\n# Sample row\nwolympics_df.sample(1)\n\n\n\n\n\n\n\n\nyear\ntype\ndiscipline\nevent\nas\nathlete_id\nnoc\nteam\nplace\ntied\nmedal\n\n\n\n\n39576\n2002.0\nWinter\nIce Hockey (Ice Hockey)\nIce Hockey, Men (Olympic)\nMathias Seger\n102297\nSUI\nSwitzerland\n11.0\nFalse\nNaN\n\n\n\n\n\n\n\nAs we see, the database contains some of the important information regarding athlete’s participation in the olympic games. Then, we can use the athlete id to find out which athletes have competed in more than one event.\n\n# Select athletes who have participated in more than one event\nmultiple_event_ath = wolympics_df.value_counts('athlete_id').to_frame().query('count&gt;1').reset_index()\n# Filter database to leave only athletes who have competed multiple events\nfiltered_olympics = wolympics_df[\n    wolympics_df['athlete_id'].isin(multiple_event_ath['athlete_id'])\n]\n# Show a few columns of the filtered data\nfiltered_olympics.head(10)\n\n\n\n\n\n\n\n\nyear\ntype\ndiscipline\nevent\nas\nathlete_id\nnoc\nteam\nplace\ntied\nmedal\n\n\n\n\n2\n1924.0\nWinter\nBobsleigh (Bobsleigh)\nFour/Five, Men (Olympic)\nCharley Stoffel\n12796\nSUI\nSwitzerland 2\nNaN\nFalse\nNaN\n\n\n3\n1928.0\nWinter\nBobsleigh (Bobsleigh)\nFour/Five, Men (Olympic)\nCharley Stoffel\n12796\nSUI\nSwitzerland 1\n8.0\nFalse\nNaN\n\n\n5\n2002.0\nWinter\nSpeed Skating (Skating)\n3,000 metres, Women (Olympic)\nClara Hughes\n13139\nCAN\nNaN\n10.0\nFalse\nNaN\n\n\n6\n2002.0\nWinter\nSpeed Skating (Skating)\n5,000 metres, Women (Olympic)\nClara Hughes\n13139\nCAN\nNaN\n3.0\nFalse\nBronze\n\n\n7\n2006.0\nWinter\nSpeed Skating (Skating)\n3,000 metres, Women (Olympic)\nClara Hughes\n13139\nCAN\nNaN\n9.0\nFalse\nNaN\n\n\n8\n2006.0\nWinter\nSpeed Skating (Skating)\n5,000 metres, Women (Olympic)\nClara Hughes\n13139\nCAN\nNaN\n1.0\nFalse\nGold\n\n\n9\n2006.0\nWinter\nSpeed Skating (Skating)\nTeam Pursuit (6 laps), Women (Olympic)\nClara Hughes\n13139\nCAN\nCanada\n2.0\nFalse\nSilver\n\n\n10\n2010.0\nWinter\nSpeed Skating (Skating)\n3,000 metres, Women (Olympic)\nClara Hughes\n13139\nCAN\nNaN\n5.0\nFalse\nNaN\n\n\n11\n2010.0\nWinter\nSpeed Skating (Skating)\n5,000 metres, Women (Olympic)\nClara Hughes\n13139\nCAN\nNaN\n3.0\nFalse\nBronze\n\n\n12\n1924.0\nWinter\nCross Country Skiing (Skiing)\n18 kilometres, Men (Olympic)\nRoberts Plūme\n16155\nLAT\nNaN\nNaN\nFalse\nNaN\n\n\n\n\n\n\n\nFrom this filtered data, we see that Charley Stoffel participated in the Olympic Games of 1924 and 1928. On the other hand, Clara Hughes participated for 3 olympic games: 2002, 2006, and 2010. Nevertheless, there are 7 entries since she competed in multiple events during the same year. If we take her story as an example, we can see that she won a Bronze medal on her first games, a gold and silver medals on her second games, and a bronze medal on her last games. Does that mean that there is a point where her performance just wouldn’t improve?\n\n\n\nSince we are interested in the difference of performance between the same athlete across the years, we want to only showcase the athletes who competed in more than one year. Moreover, to be charitable with them, we might want to take their best performance at a year in case they participated in more than one event in a single year. In our example with Clara Hughes, she participated in two events in the Winter Olympics of 2002, but she placed 10th on one event and 3rd on the other.\n\n# Group by athlete, name and year, then find the minimum (best) place\nbest_per_year = filtered_olympics.groupby(['as', 'athlete_id', 'year'])['place'].min().reset_index()\n\n# Clean up the Year and Place (converting 1924.0 to 1924)\nbest_per_year['year'] = best_per_year['year'].astype(int)\n\nbest_per_year.head()\n\n\n\n\n\n\n\n\nas\nathlete_id\nyear\nplace\n\n\n\n\n0\nA J Kitt\n87997\n1988\n26.0\n\n\n1\nA J Kitt\n87997\n1992\n9.0\n\n\n2\nA J Kitt\n87997\n1994\n17.0\n\n\n3\nA J Kitt\n87997\n1998\nNaN\n\n\n4\nA. J. Mleczko\n100464\n1998\n1.0\n\n\n\n\n\n\n\nWith this new visualization we can see how people’s performance has fluctuated throughout the years. For A J Kitt, his peak performance was during his 2nd Winter Olympics. We see that he declined after that until he did not place on his last year. Looking at him specifically, A J Kitt was born in 1968 which means he was 20 for his first Winter Olympics and 32 for his last. Particularly, he was 24 years old for his peak olympic performance.\nSurprisingly, some people have competed for up to 8 years, and at least 8 people have competed for at least 7 years.\n\nbest_per_year.groupby(['as', 'athlete_id']).size().reset_index(name='games_count').sort_values(by='games_count', ascending=False).head(10)\n\n\n\n\n\n\n\n\nas\nathlete_id\ngames_count\n\n\n\n\n9900\nNoriaki Kasai\n87815\n8\n\n\n2406\nClaudia Pechstein\n82053\n8\n\n\n11862\nSimon Ammann\n99870\n7\n\n\n11790\nSiarhei Dalidovich\n85250\n7\n\n\n5608\nJanne Ahonen\n83500\n7\n\n\n172\nAlbert Demchenko\n85156\n7\n\n\n846\nAndrus Veerpalu\n98596\n6\n\n\n6994\nKim Hyeon-Gi\n99880\n6\n\n\n12533\nTeemu Selänne\n97424\n6\n\n\n3582\nEva Tofalvi\n99564\n6\n\n\n\n\n\n\n\nWe can look at the athletes who have participated in 7 or more winter olympics to see what their performance has been like.\n\n# Identify IDs of athletes who competed in 7 or more years\nveteran_ids = best_per_year.groupby('athlete_id').size()\nveteran_ids = veteran_ids[veteran_ids &gt;= 7].index\n\n# Filter the data and remove NaN places for the plot\nplot_df = best_per_year[best_per_year['athlete_id'].isin(veteran_ids)].dropna(subset=['place'])\n\n# 3. Create the plot\nplt.figure(figsize=(12, 7))\n\nfor athlete_id in plot_df['athlete_id'].unique():\n    subset = plot_df[plot_df['athlete_id'] == athlete_id]\n    athlete_name = subset['as'].iloc[0]\n    \n    plt.plot(subset['year'], subset['place'], marker='o', linewidth=2, label=athlete_name)\n\n# 4. Styling\nplt.gca().invert_yaxis()  # Best results at the top\nplt.xlabel('Olympic Year')\nplt.ylabel('Best Place Achieved')\nplt.title('Performance Trends of Athletes with 7+ Games')\nplt.legend(title=\"Athletes\", bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(True, linestyle='--', alpha=0.5)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nOf the athletes who have competed in 7 or more games, we can see that all of them started competing later than 1992. A contributing factor to their number of participations might be that there were Winter Olympics held on 1992 and 1994 due to the schedule change to hold the Winter Olympics in different years that the summer Olympics. Out of these 6 athletes, we can see that Pechstein, Ahonen, and Demchenko had a relatively stable olympic career. Contrastingly, Kasai, Dalidovich, and Ammann had a more tumultuous olympic career. Investigating further into these 6 athletes can tell us more about their olympic career.\n\n# Load biographical data\nbios = pd.read_csv('data/bios.csv')\n# Extract data from the 6 athletes\nbios.query('athlete_id in @veteran_ids')\n\n\n\n\n\n\n\n\nathlete_id\nname\nborn_date\nborn_city\nborn_region\nborn_country\nNOC\nheight_cm\nweight_kg\ndied_date\n\n\n\n\n81401\n82053\nClaudia Pechstein\n1972-02-22\nOst-Berlin (East Berlin)\nBerlin\nGER\nGermany\n166.0\n61.0\nNaN\n\n\n82843\n83500\nJanne Ahonen\n1977-05-11\nLahti\nPäijät-Häme\nFIN\nFinland\n184.0\n66.0\nNaN\n\n\n84482\n85156\nAlbert Demchenko\n1971-11-27\nChusovoy\nPerm Kray\nRUS\nRussian Federation Unified Team\n185.0\n95.0\nNaN\n\n\n84574\n85250\nSiarhei Dalidovich\n1973-05-18\nOrsha\nVitebsk\nBLR\nBelarus\n175.0\n68.0\nNaN\n\n\n87119\n87815\nNoriaki Kasai\n1972-06-06\nShimokawa\nHokkaido\nJPN\nJapan\n176.0\n60.0\nNaN\n\n\n99074\n99870\nSimon Ammann\n1981-06-25\nGrabs\nSankt Gallen\nSUI\nSwitzerland\n171.0\n55.0\nNaN\n\n\n\n\n\n\n\nSurprisingly, all athletes are from different countries, but also countries that normally succeed in the Winter Olympics. Additionally, it seems like none of these athletes stayed around for the 2026 Olympics. Claudia Pechstein retired in 2025 and Simon Amman did not make the 2026 Switzerland Olympic team. Lastly, these 6 veterans played a variety of sports. Speed Skating: Claudia Perchstein; Ski Jumping: Janne Anohen, Simon Ammann, Noriaki Kasa; Luge: Albert Demchenko; Cross Country Ski: Siarhei Dalidovich. Having 3 veterans (7+ olympics) in ski jumping might symbolize that it has more opportunities of winning even as an older athlete."
  },
  {
    "objectID": "posts/004_dow3/dow3.html#repeating-athletes",
    "href": "posts/004_dow3/dow3.html#repeating-athletes",
    "title": "Dataset of the Week #3: Winter Olympics Data",
    "section": "",
    "text": "For a lot of athletes, the olympic games represent the peak of their athletic career. Nevertheless, some of them might have started competing at such a young age that they’re able to participate in multiple instances of the olympic games. We can take look at a database of the winter olympics to find out which athletes have participated in more than one event.\n\n# Set Up\nimport pandas as pd\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n# Load Data\nwolympics_df = pd.read_csv('data/winter_olympics_medals.csv')\n# Sample row\nwolympics_df.sample(1)\n\n\n\n\n\n\n\n\nyear\ntype\ndiscipline\nevent\nas\nathlete_id\nnoc\nteam\nplace\ntied\nmedal\n\n\n\n\n39576\n2002.0\nWinter\nIce Hockey (Ice Hockey)\nIce Hockey, Men (Olympic)\nMathias Seger\n102297\nSUI\nSwitzerland\n11.0\nFalse\nNaN\n\n\n\n\n\n\n\nAs we see, the database contains some of the important information regarding athlete’s participation in the olympic games. Then, we can use the athlete id to find out which athletes have competed in more than one event.\n\n# Select athletes who have participated in more than one event\nmultiple_event_ath = wolympics_df.value_counts('athlete_id').to_frame().query('count&gt;1').reset_index()\n# Filter database to leave only athletes who have competed multiple events\nfiltered_olympics = wolympics_df[\n    wolympics_df['athlete_id'].isin(multiple_event_ath['athlete_id'])\n]\n# Show a few columns of the filtered data\nfiltered_olympics.head(10)\n\n\n\n\n\n\n\n\nyear\ntype\ndiscipline\nevent\nas\nathlete_id\nnoc\nteam\nplace\ntied\nmedal\n\n\n\n\n2\n1924.0\nWinter\nBobsleigh (Bobsleigh)\nFour/Five, Men (Olympic)\nCharley Stoffel\n12796\nSUI\nSwitzerland 2\nNaN\nFalse\nNaN\n\n\n3\n1928.0\nWinter\nBobsleigh (Bobsleigh)\nFour/Five, Men (Olympic)\nCharley Stoffel\n12796\nSUI\nSwitzerland 1\n8.0\nFalse\nNaN\n\n\n5\n2002.0\nWinter\nSpeed Skating (Skating)\n3,000 metres, Women (Olympic)\nClara Hughes\n13139\nCAN\nNaN\n10.0\nFalse\nNaN\n\n\n6\n2002.0\nWinter\nSpeed Skating (Skating)\n5,000 metres, Women (Olympic)\nClara Hughes\n13139\nCAN\nNaN\n3.0\nFalse\nBronze\n\n\n7\n2006.0\nWinter\nSpeed Skating (Skating)\n3,000 metres, Women (Olympic)\nClara Hughes\n13139\nCAN\nNaN\n9.0\nFalse\nNaN\n\n\n8\n2006.0\nWinter\nSpeed Skating (Skating)\n5,000 metres, Women (Olympic)\nClara Hughes\n13139\nCAN\nNaN\n1.0\nFalse\nGold\n\n\n9\n2006.0\nWinter\nSpeed Skating (Skating)\nTeam Pursuit (6 laps), Women (Olympic)\nClara Hughes\n13139\nCAN\nCanada\n2.0\nFalse\nSilver\n\n\n10\n2010.0\nWinter\nSpeed Skating (Skating)\n3,000 metres, Women (Olympic)\nClara Hughes\n13139\nCAN\nNaN\n5.0\nFalse\nNaN\n\n\n11\n2010.0\nWinter\nSpeed Skating (Skating)\n5,000 metres, Women (Olympic)\nClara Hughes\n13139\nCAN\nNaN\n3.0\nFalse\nBronze\n\n\n12\n1924.0\nWinter\nCross Country Skiing (Skiing)\n18 kilometres, Men (Olympic)\nRoberts Plūme\n16155\nLAT\nNaN\nNaN\nFalse\nNaN\n\n\n\n\n\n\n\nFrom this filtered data, we see that Charley Stoffel participated in the Olympic Games of 1924 and 1928. On the other hand, Clara Hughes participated for 3 olympic games: 2002, 2006, and 2010. Nevertheless, there are 7 entries since she competed in multiple events during the same year. If we take her story as an example, we can see that she won a Bronze medal on her first games, a gold and silver medals on her second games, and a bronze medal on her last games. Does that mean that there is a point where her performance just wouldn’t improve?"
  },
  {
    "objectID": "posts/004_dow3/dow3.html#athletes-across-multiple-years",
    "href": "posts/004_dow3/dow3.html#athletes-across-multiple-years",
    "title": "Dataset of the Week #3: Winter Olympics Data",
    "section": "",
    "text": "Since we are interested in the difference of performance between the same athlete across the years, we want to only showcase the athletes who competed in more than one year. Moreover, to be charitable with them, we might want to take their best performance at a year in case they participated in more than one event in a single year. In our example with Clara Hughes, she participated in two events in the Winter Olympics of 2002, but she placed 10th on one event and 3rd on the other.\n\n# Group by athlete, name and year, then find the minimum (best) place\nbest_per_year = filtered_olympics.groupby(['as', 'athlete_id', 'year'])['place'].min().reset_index()\n\n# Clean up the Year and Place (converting 1924.0 to 1924)\nbest_per_year['year'] = best_per_year['year'].astype(int)\n\nbest_per_year.head()\n\n\n\n\n\n\n\n\nas\nathlete_id\nyear\nplace\n\n\n\n\n0\nA J Kitt\n87997\n1988\n26.0\n\n\n1\nA J Kitt\n87997\n1992\n9.0\n\n\n2\nA J Kitt\n87997\n1994\n17.0\n\n\n3\nA J Kitt\n87997\n1998\nNaN\n\n\n4\nA. J. Mleczko\n100464\n1998\n1.0\n\n\n\n\n\n\n\nWith this new visualization we can see how people’s performance has fluctuated throughout the years. For A J Kitt, his peak performance was during his 2nd Winter Olympics. We see that he declined after that until he did not place on his last year. Looking at him specifically, A J Kitt was born in 1968 which means he was 20 for his first Winter Olympics and 32 for his last. Particularly, he was 24 years old for his peak olympic performance.\nSurprisingly, some people have competed for up to 8 years, and at least 8 people have competed for at least 7 years.\n\nbest_per_year.groupby(['as', 'athlete_id']).size().reset_index(name='games_count').sort_values(by='games_count', ascending=False).head(10)\n\n\n\n\n\n\n\n\nas\nathlete_id\ngames_count\n\n\n\n\n9900\nNoriaki Kasai\n87815\n8\n\n\n2406\nClaudia Pechstein\n82053\n8\n\n\n11862\nSimon Ammann\n99870\n7\n\n\n11790\nSiarhei Dalidovich\n85250\n7\n\n\n5608\nJanne Ahonen\n83500\n7\n\n\n172\nAlbert Demchenko\n85156\n7\n\n\n846\nAndrus Veerpalu\n98596\n6\n\n\n6994\nKim Hyeon-Gi\n99880\n6\n\n\n12533\nTeemu Selänne\n97424\n6\n\n\n3582\nEva Tofalvi\n99564\n6\n\n\n\n\n\n\n\nWe can look at the athletes who have participated in 7 or more winter olympics to see what their performance has been like.\n\n# Identify IDs of athletes who competed in 7 or more years\nveteran_ids = best_per_year.groupby('athlete_id').size()\nveteran_ids = veteran_ids[veteran_ids &gt;= 7].index\n\n# Filter the data and remove NaN places for the plot\nplot_df = best_per_year[best_per_year['athlete_id'].isin(veteran_ids)].dropna(subset=['place'])\n\n# 3. Create the plot\nplt.figure(figsize=(12, 7))\n\nfor athlete_id in plot_df['athlete_id'].unique():\n    subset = plot_df[plot_df['athlete_id'] == athlete_id]\n    athlete_name = subset['as'].iloc[0]\n    \n    plt.plot(subset['year'], subset['place'], marker='o', linewidth=2, label=athlete_name)\n\n# 4. Styling\nplt.gca().invert_yaxis()  # Best results at the top\nplt.xlabel('Olympic Year')\nplt.ylabel('Best Place Achieved')\nplt.title('Performance Trends of Athletes with 7+ Games')\nplt.legend(title=\"Athletes\", bbox_to_anchor=(1.05, 1), loc='upper left')\nplt.grid(True, linestyle='--', alpha=0.5)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nOf the athletes who have competed in 7 or more games, we can see that all of them started competing later than 1992. A contributing factor to their number of participations might be that there were Winter Olympics held on 1992 and 1994 due to the schedule change to hold the Winter Olympics in different years that the summer Olympics. Out of these 6 athletes, we can see that Pechstein, Ahonen, and Demchenko had a relatively stable olympic career. Contrastingly, Kasai, Dalidovich, and Ammann had a more tumultuous olympic career. Investigating further into these 6 athletes can tell us more about their olympic career.\n\n# Load biographical data\nbios = pd.read_csv('data/bios.csv')\n# Extract data from the 6 athletes\nbios.query('athlete_id in @veteran_ids')\n\n\n\n\n\n\n\n\nathlete_id\nname\nborn_date\nborn_city\nborn_region\nborn_country\nNOC\nheight_cm\nweight_kg\ndied_date\n\n\n\n\n81401\n82053\nClaudia Pechstein\n1972-02-22\nOst-Berlin (East Berlin)\nBerlin\nGER\nGermany\n166.0\n61.0\nNaN\n\n\n82843\n83500\nJanne Ahonen\n1977-05-11\nLahti\nPäijät-Häme\nFIN\nFinland\n184.0\n66.0\nNaN\n\n\n84482\n85156\nAlbert Demchenko\n1971-11-27\nChusovoy\nPerm Kray\nRUS\nRussian Federation Unified Team\n185.0\n95.0\nNaN\n\n\n84574\n85250\nSiarhei Dalidovich\n1973-05-18\nOrsha\nVitebsk\nBLR\nBelarus\n175.0\n68.0\nNaN\n\n\n87119\n87815\nNoriaki Kasai\n1972-06-06\nShimokawa\nHokkaido\nJPN\nJapan\n176.0\n60.0\nNaN\n\n\n99074\n99870\nSimon Ammann\n1981-06-25\nGrabs\nSankt Gallen\nSUI\nSwitzerland\n171.0\n55.0\nNaN\n\n\n\n\n\n\n\nSurprisingly, all athletes are from different countries, but also countries that normally succeed in the Winter Olympics. Additionally, it seems like none of these athletes stayed around for the 2026 Olympics. Claudia Pechstein retired in 2025 and Simon Amman did not make the 2026 Switzerland Olympic team. Lastly, these 6 veterans played a variety of sports. Speed Skating: Claudia Perchstein; Ski Jumping: Janne Anohen, Simon Ammann, Noriaki Kasa; Luge: Albert Demchenko; Cross Country Ski: Siarhei Dalidovich. Having 3 veterans (7+ olympics) in ski jumping might symbolize that it has more opportunities of winning even as an older athlete."
  },
  {
    "objectID": "posts/002_dow1/dow1.html",
    "href": "posts/002_dow1/dow1.html",
    "title": "Dataset of the Week #1: The Weather in Philadelphia",
    "section": "",
    "text": "Is the weather in our favor for Spring Fling 2026?\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\nweather_df = pd.read_csv('data/philadelphia_weather_2005_to_2025.csv')\nweather_df = weather_df.assign(date=pd.to_datetime(weather_df['date']))\n\nAs a past Spring Fling Daytime director, the weather during the weekend has always been an important part of the experience. From being really cold at 6 am for setup to raining during the night so the field is wet, weather can make the experience for the volunteers and attendees more or less pleasant. Last year, it rained the night between Concerts and Daytime, but it also rained on and off between 6am and 3 pm of Saturday, which caused the festival to be delayed by 30 minutes.\n\n\nHow is it looking Spring Fling 2026?\nThis year, Spring Fling weekend will be on April 17 and 18. Using past 21 years of data, we might be able to estimate what the weather will be like for Fling Weekend.\n\nconcert26 = pd.to_datetime(\n    dict(\n        year=weather_df[\"date\"].dt.year,\n        month=4,\n        day=17\n    )\n)\n\nfling_end = concert26 + pd.Timedelta(days=1)\n\n\nfweekend_filter = (weather_df['date']&gt;=concert26) & (weather_df['date']&lt;=fling_end)\n\n\nflingweekend_df = (weather_df.\n                    loc[fweekend_filter].\n                    groupby('year')[['high','low','rain']].\n                    agg(\n                       [min,max,np.mean, np.std]\n                    ).\n                    round(1)\n                )\n\nAt the time of setup, it is normally along the coldest parts of the day, so we can look at the lowest temperatures of April 17 and 18.\n\nflingweekend_df['low','mean'].plot(kind='line', style='-o', color='b')\nplt.axhline(flingweekend_df[('low','mean')].mean(), color='r', linestyle='--', label='Mean')\nplt.title('Philadelphia Average Low temperature on April 17 & 18  2005-2025')\nplt.ylabel('Temperature (°F)')\nplt.xlabel('Year')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nAs we can see, the coldest it has been was around 35 degrees in 2022. On the contrary, the the low has been higher than 55 in years like 2012. On average, the low during April 17 and 18 has been around 46 degrees Farenheit (or 7 degrees Celsius).\nWhen looking at the highest temperatures throughout the days, we can see that the lowest highs happened on 2018, 2020, and 2022 with 50 degrees. On the contrary, we have gotten as high as 80 degrees on years like 2008. On average, the high for the pair of days seem to be around 65 degrees.\n\nflingweekend_df['high','mean'].plot(kind='line', style='-o', color='orange')\nplt.axhline(flingweekend_df[('high','mean')].mean(), color='r', linestyle='--', label='Mean')\nplt.title('Philadelphia Average High temperature on April 17 & 18  2005-2025')\nplt.ylabel('Temperature (°F)')\nplt.xlabel('Year')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nThen, according to data from previous years, the average range of temperature on April 17 and April 18 seems to be from 45 to 65, which seems like a comfortable range. It might be useful for the directors and volunteers to layer up so they stay warm during set up, but they are not that hot during the festival itself.\n\nWhat about rain?\nRain can be one of the less productive things to happen on Fling Weekend. In addition to making setup more uncomfortable, rain can make the operations cost of fling more expensive. If it rains during the Friday of the concert, it might make workers stop setting up the floor, which significantly increases labor costs.\n\nflingweekend_df['rain','max'].plot(kind='line', style='-o')\nplt.axhline(flingweekend_df[('rain','max')].mean(), color='r', linestyle='--', label='Mean')\nplt.title('Philadelphia Inches of Rain on April 17 & 18  2005-2025')\nplt.ylabel('Inches of Rain')\nplt.xlabel('Year')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\nAs shown in the graph, it looks like on average, there has been around 0.1 inches of rain during April 17 and 18 over the years. There has only been one year in which it rained torrentialy up to 1.1 inches.\nIf we take into account this data from previus year, it looks like it might be a good year for Spring Fling in terms of weather."
  }
]